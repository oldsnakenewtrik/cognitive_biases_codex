**\# We Need To Act Fast**

When humans problem solve, begin a logical reasoning or complex problem solving assignment they are faced with the scenario, “We Need To Act Fast\!”, based on limitations to their brain processing power.

\#\# Human Information Processing Tendencies Regarding Acting Fast Or Having Finite Time To React

\#\#\# To act, we must be confident we can make an impact and feel what we do is important

\#\#\#\# Peltzman effect

The Peltzman effect is the tendency for people to increase risky behavior when safety measures are introduced, offsetting some of the intended benefits. Originating in economics and traffic safety research by Sam Peltzman (1975), it suggests that mandated safety features (like seat belts) may lead drivers to drive more recklessly. The mechanism is **risk compensation**: people balance perceived safety against desired risk-taking. For example, after airbags became standard, accident survival rates improved, but some studies showed no proportional decline in fatalities because drivers felt “safer” and took more chances.

\#\#\#\# Risk compensation

Risk compensation is the behavioral adjustment people make when their perceived level of safety changes, often engaging in riskier actions when protection increases. Rooted in psychology and economics, it explains why interventions meant to reduce harm don’t always yield the expected benefits. The principle is that people maintain a personal “risk thermostat” — when safety rises, they increase risk-taking to restore balance. For instance, cyclists may ride faster or less cautiously when wearing a helmet, partly negating the protective effect.

\#\#\#\# Effort justification

Effort justification is the tendency to assign greater value to an outcome when more effort has been invested in achieving it. This concept comes from **cognitive dissonance theory** (Festinger, 1957), where people resolve the discomfort of “I worked hard for this, but it’s not that great” by inflating the reward’s worth. The core mechanism is dissonance reduction: people align their attitudes to justify their behavior. A common example is fraternity hazing, where individuals who endure grueling initiation rituals report greater loyalty and satisfaction with membership.

\#\#\#\# Trait ascription bias

Trait ascription bias is the tendency to view one’s own personality and behavior as more variable and context-dependent, while seeing others’ traits as more stable and predictable. It stems from **asymmetry of perspective**: we have access to our internal states and situational constraints but judge others mainly on observed behavior. This bias supports overgeneralization of others’ actions into fixed traits. For example, you may excuse yourself for being irritable because you’re tired, but label a colleague as generally rude for the same behavior.

\#\#\#\# Defensive attribution error

The defensive attribution error occurs when people attribute more blame to others for negative outcomes, especially when they perceive themselves as potentially vulnerable to similar events. This bias is rooted in a desire for psychological protection: distancing oneself from the victim’s situation by assuming they caused their misfortune reduces personal anxiety. For instance, if someone hears about a car accident, they may assume the driver was careless rather than unlucky, reassuring themselves that being careful will prevent the same fate.

\#\#\#\# Illusory superiority

Illusory superiority is the cognitive bias where individuals overestimate their own qualities, skills, or performance relative to others. Known as the “better-than-average effect,” it arises from **self-enhancement motives** and limited access to others’ true abilities. The mechanism is biased self-assessment: people recall successes more readily and discount failures. A common example is surveys where most drivers rate themselves as above-average, which is statistically impossible.

\#\#\#\# Illusion of control

The illusion of control is the belief that one can influence outcomes that are actually determined by chance. First identified by psychologist Ellen Langer (1975), it reflects **cognitive overconfidence** and the human tendency to misinterpret randomness as controllable. The mechanism involves attributing causal power to one’s actions where none exists. For example, gamblers often believe throwing dice gently will yield lower numbers, or investors may think timing the market gives them control over inherently unpredictable fluctuations.

\#\#\#\# Actor-observer bias

The actor-observer bias is the tendency to attribute our own behavior to situational factors while attributing others’ behavior to their stable traits or dispositions. It arises because we have more awareness of our own context and constraints but only see others’ actions externally. The mechanism is perspective-based asymmetry: actors see circumstances; observers see personalities. For example, you might explain your own lateness as due to traffic, but assume a colleague is late because they are irresponsible.

\#\#\#\# Self-serving bias

The self-serving bias is the tendency to credit successes to internal qualities (like talent or effort) while blaming failures on external factors (like bad luck or unfair conditions). It stems from a need to protect self-esteem and maintain a positive self-image. The mechanism is selective attribution that enhances personal value while minimizing personal fault. For instance, a student may attribute a high grade to intelligence but a poor grade to an unfair exam.

\#\#\#\# Barnum effect

The Barnum effect is the tendency for people to accept vague, general personality descriptions as uniquely applicable to themselves. Originating from psychology research into astrology and fortune-telling, it reflects people’s desire for self-relevance and meaning. The mechanism involves interpreting broad statements in a self-confirming way. For example, many will agree with horoscopes saying they are “sometimes outgoing but sometimes reserved,” even though it applies to most people.

\#\#\#\# Forer effect

The Forer effect is essentially the same phenomenon as the Barnum effect, named after psychologist Bertram Forer, who demonstrated it in a 1949 study. He gave students identical generic personality profiles and most rated them as highly accurate. The mechanism is the same: people project personal meaning onto vague, flattering, or broadly true statements. This explains why personality tests with nonspecific results often feel strikingly accurate to individuals.

\#\#\#\# Optimism bias

Optimism bias is the tendency to overestimate the likelihood of positive outcomes and underestimate negative ones for ourselves. It arises from motivational psychology and self-protection mechanisms that favor hope and positive expectation. The mechanism is distorted risk perception: people expect to avoid misfortune even when probabilities don’t support it. For example, many believe they are less likely than average to get divorced or experience serious illness.

\#\#\#\# Egocentric bias

Egocentric bias is the tendency to overemphasize one’s own perspective, contributions, or centrality in events compared to others. It stems from the fact that we have privileged access to our own experiences and less to others’. The mechanism is availability: our own role and viewpoint dominate memory and attention. For example, in group projects, most members believe they contributed more than their peers, even when this cannot be true for everyone.

\#\#\#\# Dunning-Kruger effect

The Dunning-Kruger effect is a cognitive bias where people with low ability in a domain overestimate their competence, while highly skilled individuals may underestimate themselves. Identified by David Dunning and Justin Kruger (1999), it arises from the metacognitive problem that incompetence limits the ability to recognize one’s own mistakes. The mechanism is lack of self-awareness: those with fewer skills also lack the knowledge to evaluate skill properly. For example, poor performers on logic or grammar tests often rate their performance as above average.

\#\#\#\# Lake Wobegone effect

The Lake Wobegone effect is the human tendency to overestimate one’s abilities relative to others, named after the fictional town in Garrison Keillor’s stories where “all the children are above average.” It reflects illusory superiority and self-enhancement motives. The mechanism is biased self-assessment and selective memory of successes. For example, surveys consistently find that the majority of people consider themselves better-than-average drivers.

\#\#\#\# Hard-easy effect

The hard-easy effect is the tendency for people to be overconfident about their ability to solve difficult tasks and underconfident about easy ones. It arises from miscalibrated confidence judgments in psychology research on decision-making. The mechanism is anchoring confidence more on perceived challenge than actual performance statistics. For example, people may believe they are more likely than they are to solve a very hard trivia question, while underestimating their accuracy on simple questions.

\#\#\#\# False consensus effect

The false consensus effect is the tendency to overestimate how much others share our beliefs, values, or behaviors. It arises from projecting our own perspective onto others and assuming it’s typical. The mechanism is self-centered sampling: we use our own experiences as a guide to estimate population norms. For instance, a person who eats fast food regularly may assume that “most people” also do so, even if that’s not true.

\#\#\#\# Third-person effect

The third-person effect is the belief that others are more affected by media messages or persuasion than oneself. It was first proposed in communication research by W. Phillips Davison (1983). The mechanism is self-enhancement: assuming immunity to influence while considering others more gullible. For example, people may argue that violent video games affect society at large but not their own behavior.

\#\#\#\# Social desirability effect

The social desirability effect is the tendency for people to answer questions or behave in ways that they think will be viewed favorably by others, rather than reflecting their true beliefs or actions. It arises in psychology and survey research from self-presentation motives. The mechanism is impression management: modifying responses to align with social norms. For example, people may underreport alcohol consumption or overreport charitable giving in surveys.

\#\#\#\# Overconfidence effect

The overconfidence effect is the pervasive tendency for people’s subjective confidence in their judgments to exceed their actual accuracy. It arises across psychology, economics, and decision science. The mechanism is flawed calibration: people rely on internal feelings of certainty rather than objective probability. For instance, a stock trader might feel “sure” about predicting market movement, but actual outcomes show much lower accuracy than their confidence implies.

\#\#\# To stay focused, we favor the immediate, relatable thing in front of us

\#\#\#\# Identifiable victim effect

The identifiable victim effect is the tendency for people to show stronger compassion and willingness to help when aid is directed toward a single, identifiable individual rather than a large, anonymous group. It arises from emotional psychology — personalizing suffering creates a vivid mental image that drives empathy. The mechanism is affective salience: identifiable stories evoke stronger emotions than abstract statistics. For example, people are more likely to donate when shown the picture and story of one child in need rather than when told millions face starvation.

\#\#\#\# Appeal to novelty

The appeal to novelty is a logical fallacy in which something is assumed to be superior or more correct simply because it is new. It is rooted in marketing, persuasion, and human attraction to innovation. The mechanism is heuristic substitution: novelty is used as a proxy for quality without evidence. For example, consumers may assume a newly released smartphone is better than the previous model purely because it is newer, even if the upgrades are minimal.

\#\#\#\# Hyperbolic discounting

Hyperbolic discounting is the tendency to prefer smaller, immediate rewards over larger, delayed ones, even when waiting yields a greater payoff. This concept comes from behavioral economics and time-preference research. The mechanism is steep temporal discounting: people disproportionately devalue future outcomes compared to near-term ones. For example, someone may choose $50 today instead of $100 in a year, even though the latter is objectively better.

\#\#\# To get things done, we tend to complete things we've invested time and energy in

\#\#\#\# Backfire effect

The backfire effect is the phenomenon where presenting evidence against someone’s belief makes them cling to that belief more strongly instead of changing their mind. Rooted in cognitive psychology and political science, it arises from identity protection and motivated reasoning. The mechanism is defensive cognition: counter-arguments trigger resistance rather than openness. For example, when shown data disproving a political claim, strong partisans may double down on their position instead of revising it.

\#\#\#\# Endowment effect

The endowment effect is the bias where people assign greater value to things simply because they own them. It is linked to behavioral economics and prospect theory. The mechanism is loss aversion: giving something up feels worse than acquiring it. For instance, someone may demand $200 to sell a ticket they own but would have been unwilling to pay more than $100 to buy it in the first place.

\#\#\#\# Processing difficulty effect

The processing difficulty effect, also called the disfluency effect, is the tendency for information that is harder to process (e.g., unusual fonts, complex language) to be remembered better or judged more carefully. It comes from cognitive psychology research on fluency and memory. The mechanism is deeper cognitive engagement: when processing is difficult, people invest more effort, which improves encoding. For example, a study showed students remembered material presented in harder-to-read fonts better than easy-to-read ones.

\#\#\#\# Pseudocertainty effect

The pseudocertainty effect is a cognitive bias where people prefer options framed as eliminating risk in one stage of a decision, even when overall risk remains the same. It comes from prospect theory (Tversky & Kahneman). The mechanism is framing: people overweight the appeal of “certainty” in part of a problem, ignoring the full probabilities. For example, people may prefer a medical treatment that “completely eliminates a 20% risk” in one subgroup, even if the total risk reduction is no better than an alternative.

\#\#\#\# Disposition effect

The disposition effect is the tendency for investors to sell winning assets too early (locking in gains) and hold onto losing assets too long (avoiding realizing losses). It originates from behavioral finance. The mechanism is asymmetric risk perception: investors are risk-averse with gains but risk-seeking with losses, consistent with prospect theory. For example, a trader may sell a stock after a 10% gain to “secure profit” but keep a losing stock in hopes it recovers, even when evidence suggests otherwise.

\#\#\#\# Zero-risk bias  
Zero-risk bias is the tendency to prefer options that completely eliminate a small risk, even when alternatives reduce overall risk more effectively. It arises from people’s preference for certainty and aversion to ambiguity. The mechanism is overvaluing absolute safety: eliminating one risk feels more satisfying than proportionally reducing larger risks. For example, people may fund a program that fully removes a minor hazard (like a small toxin exposure) rather than one that halves a much larger risk (like air pollution).

\#\#\#\# Unit bias

Unit bias is the tendency to view a single unit of something as the proper or optimal amount, regardless of its actual size or value. It comes from psychology and behavioral economics research on eating and consumption. The mechanism is heuristic-driven: people assume the “default unit” is the right amount. For instance, diners often eat an entire plate or candy bar because it’s presented as one portion, even if it’s oversized.

\#\#\#\# IKEA effect

The IKEA effect is the tendency for people to place disproportionately high value on things they have partially created themselves. It was named after the furniture brand, whose customers often assemble their own products. The mechanism is effort-based valuation: personal labor increases emotional attachment and perceived worth. For example, someone may prize a bookshelf they built from a kit more than an equivalent pre-assembled one.

\#\#\#\# Loss aversion

Loss aversion is the principle that people experience losses more intensely than equivalent gains. Central to prospect theory (Kahneman & Tversky), it explains why losses “loom larger” psychologically than potential wins. The mechanism is asymmetry in valuation: the pain of losing $100 feels greater than the joy of gaining $100. For example, investors are often reluctant to sell losing stocks, preferring to avoid realizing a loss even at the cost of better returns.

\#\#\#\# Generation effect

The generation effect is the finding that information is better remembered when people actively generate it themselves rather than passively receiving it. Rooted in cognitive psychology, it highlights the role of active processing in memory. The mechanism is deeper encoding: generating responses requires more cognitive effort, strengthening recall. For example, students remember words better if they generate synonyms instead of just reading them.

\#\#\#\# Escalation of commitment

Escalation of commitment is the tendency to continue investing in a failing course of action due to prior investments of time, money, or effort. It is closely related to the sunk cost fallacy but emphasizes ongoing commitment in decision-making. The mechanism is psychological entrapment: people rationalize persistence to avoid admitting failure. For example, a company may keep funding a failing project because of the millions already spent, even when evidence suggests it should be abandoned.

\#\#\#\# Irrational escalation

Irrational escalation, also known as escalation of commitment, refers specifically to continuing to rationalize additional investments in a decision despite negative outcomes. It emphasizes the irrational nature of persisting against contrary evidence. The mechanism is self-justification and consistency pressure: people don’t want to appear wrong, so they double down. For example, in auctions, bidders often overpay because they don’t want to lose after already investing effort and money.

\#\#\#\# Sunk cost fallacy

The sunk cost fallacy is the bias of continuing a behavior or investment based on previously invested resources, even when future costs outweigh expected benefits. It is a cornerstone of behavioral economics and decision-making research. The mechanism is loss aversion and cognitive dissonance: abandoning an investment feels like admitting waste, so people persist. For example, someone may keep attending a course they dislike because they already paid for it, even though quitting would save time and stress.

\#\#\# To avoid mistakes, we aim to preserve autonomy and group status, and avoid irreversible decisions

\#\#\#\# Status quo bias

Status quo bias is the preference to keep things the same by avoiding change, even when alternatives may be better. It arises from loss aversion and inertia: potential losses from change feel stronger than potential gains. The mechanism is psychological comfort — familiarity feels safer than uncertainty. For example, employees may resist switching to a new software system even if it improves efficiency.

\#\#\#\# Social comparison effect

The social comparison effect is the tendency to evaluate ourselves by comparing with others, often influencing self-esteem, motivation, and behavior. It comes from social comparison theory (Festinger, 1954). The mechanism is relative evaluation: people define success not in absolute terms but against peers. For instance, a student may feel accomplished until learning classmates scored higher, which lowers their satisfaction.

\#\#\#\# Decoy effect

The decoy effect occurs when the presence of a less attractive option (the "decoy") influences people to choose a target option over an alternative. It arises in marketing and decision-making research. The mechanism is asymmetric dominance: the decoy makes one option look superior by comparison. For example, if a small popcorn costs $3, a large $7, and a medium $6.50, many buyers choose the large — because the medium makes it look like a better deal.

\#\#\#\# Reactance

Reactance is the psychological response where people resist or do the opposite of what they’re told when they perceive their freedom of choice is being threatened. Rooted in reactance theory (Brehm, 1966), it reflects a motivational drive to restore autonomy. The mechanism is defensive opposition: restrictions trigger resistance to reassert control. For example, teenagers may break rules precisely because parents forbid certain behaviors.

\#\#\#\# Reverse psychology

Reverse psychology is a persuasion technique where someone advocates the opposite of what they want, expecting the other person’s reactance to push them toward the desired action. It exploits the human desire for autonomy and control. The mechanism is strategic use of reactance: by “forbidding” or dismissing something, the persuader makes it more appealing. For instance, telling a child “You probably won’t like these vegetables” may increase their willingness to try them.

\#\#\#\# System justification

System justification is the tendency to defend and rationalize existing social, economic, or political systems, even when they disadvantage us. It stems from the psychological need for order, stability, and reduced cognitive dissonance. The mechanism is motivated reasoning: people believe “the system is fair” because alternatives create discomfort or uncertainty. For example, low-income individuals may support policies favoring the wealthy, believing that the system is merit-based and just.

\#\#\# We favor simple-looking options and complete information over complex, ambiguous options

\#\#\#\# Less-is-better effect

The less-is-better effect is the tendency for people to prefer a smaller, objectively inferior option when judged alone, but recognize the larger, superior option as better when compared directly. It arises from reliance on context and framing in judgment. The mechanism is evaluability: people focus on salient attributes (like quality) over quantity when options are separate. For example, people may value a gift of a $45 scarf more than a $55 coat when considered individually, but reverse the preference when both are presented together.

\#\#\#\# Occam’s razor

Occam’s razor is a principle of reasoning that states the simplest explanation, requiring the fewest assumptions, is usually the best. Originating from the 14th-century philosopher William of Ockham, it is widely applied in science, logic, and philosophy. The mechanism is parsimony: unnecessary complexity increases the risk of error. For instance, in diagnosing a patient, doctors often prefer the simplest condition that explains all symptoms rather than assuming multiple rare diseases.

\#\#\#\# Conjunction fallacy

The conjunction fallacy is the error of assuming that specific conditions are more probable than a single general one. It arises from representativeness heuristics — people judge likelihood by how much something fits a stereotype rather than probability logic. The mechanism is misunderstanding probability: the probability of A and B together cannot exceed the probability of A alone. The famous example is the “Linda problem”: people judge “Linda is a bank teller and feminist” as more likely than “Linda is a bank teller,” even though logically it cannot be.

\#\#\#\# Law of Triviality

The law of triviality, also called bike-shedding, is the tendency for groups to spend disproportionate time discussing minor, easy-to-grasp issues rather than major, complex ones. Coined by C. Northcote Parkinson, it reflects comfort with simple details and avoidance of harder topics. The mechanism is accessibility: trivial details are easier for everyone to debate. For example, a committee may argue extensively about the color of a new office bike shed but give little attention to a multimillion-dollar budget decision.

\#\#\#\# Bike-shedding effect

The bike-shedding effect is the popular term for the law of triviality. It describes how groups overfocus on small, trivial issues because they are easier to understand and debate, while neglecting larger, more important problems. For example, a board might spend an hour debating the font on a report cover but only minutes on a major policy shift.

\#\#\#\# Rhyme-as-reason effect

The rhyme-as-reason effect is the cognitive bias where rhyming statements are judged as more truthful or accurate than non-rhyming ones. Rooted in processing fluency, rhymes feel easier to remember and thus more credible. The mechanism is fluency heuristic: smooth, pleasant processing is mistaken for truth. For example, the phrase “What sobriety conceals, alcohol reveals” seems more accurate than an equivalent non-rhyming version.

\#\#\#\# Belief bias

Belief bias is the tendency to judge the strength of an argument based on the believability of its conclusion, rather than logical validity. It arises in reasoning and critical thinking research. The mechanism is heuristic override: prior beliefs dominate formal logic evaluation. For example, people may accept an invalid argument like “All roses are flowers, some flowers fade quickly, therefore all roses fade quickly” if they believe roses do fade quickly.

\#\#\#\# Information bias

Information bias is the tendency to seek or rely on information that does not affect action or decision outcomes. It stems from the mistaken belief that more information is always better. The mechanism is cognitive comfort: people prefer the feeling of completeness, even if data is irrelevant. For instance, a doctor might order extra tests for a patient even though the results will not change the treatment plan.

\#\#\#\# Ambiguity bias

Ambiguity bias is the tendency to favor options with known probabilities over those with unknown or ambiguous ones, even if the ambiguous choice may offer better outcomes. It is closely related to the Ellsberg paradox in decision theory. The mechanism is avoidance of uncertainty: people prefer clarity and predictability. For example, investors may prefer bonds with guaranteed returns over unfamiliar but potentially more profitable ventures with uncertain odds.